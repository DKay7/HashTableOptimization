* Исследование и оптимизация хэш-таблицы
  :PROPERTIES:
  :CUSTOM_ID: исследование-и-оптимизация-хэш-таблицы
  :END:

Данное задание посвящено написанию, исследованию работы и оптимизации
структуры данных хэш таблица.

** Некоторые детали реализации
   :PROPERTIES:
   :CUSTOM_ID: некоторые-детали-реализации
   :END:

В первую очередь, хотелось бы отметить некоторые отличительные черты
данной хэш-таблицы. 1. Коллизии разрешаются методом цепочек 2. Сама
таблица умеет расширяться, когда коэффициент заполнения (количество
элементов, на одну ячейку хэш-таблицы) превышает 1.5 3. Хэш-таблица
является "кэш-френдли", то есть реализация подразумевает уменьшение
кэш-мисов. Достигнуто это следующим образом: 1. Во-первых, связный
список, используемый для разрешения коллизий представляет из себя
массив, то есть хранится в памяти последовательно, что увеличивает
вероятность того, что все элементы списка окажутся в кэше 2. Во-вторых,
метод цепочек немного видоизменен. Стандратная реализация предполагает,
что каждый элемент хэш-таблицы имеет свой связный список, в который
кладутся элементы при возникновении коллизий. В данном же проекте,
связный список -- один, а каждый элемент хранит начало подсписка и
длину. Такое решение также должно уменьшать количество кэшмисов, потому
что и сама таблица, и связный список -- массивы, хранящиеся в памяти
последовательно. В дальнейшем, один элемент хэш-таблицы (то есть
подсписок и его длину) мы будем называть бакетом (от англ. bucket --
ведро).

** Данные
   :PROPERTIES:
   :CUSTOM_ID: данные
   :END:

Теперь пару слов о данных, на которых производились тесты. Для
объективности тестирования, данных должно быть много, поэтому было
принято решение взять англо-русский словарь на 64000 слов и выражений.
После удаления дубликатов, пустых значений (без перевода), и слишком
длинных строк, в словаре осталось около 55000 строк формата "английское
выражение -- перевод". Ключом хэштаблицы являлась фраза на английском, а
значением -- перевод.

** Тестирование
   :PROPERTIES:
   :CUSTOM_ID: тестирование
   :END:

В первую очередь, необходимо выбрать наилучшую хэш-функцию, дающую
минимум коллизий. Для тестирования были предложены следующие функции:

1. =const_hash=:

#+BEGIN_SRC C++
    uint64_t const_hash (char* str)
    {   
        (void ) str;
        return 1ul;
    }
#+END_SRC

2. =first_letter_code_hash=:
   =C++ uint64_t first_letter_code_hash (char* str) {     assert (str);  return (uint64_t)str[0]; }=C++

3. =len_hash=:

#+BEGIN_SRC C++
    uint64_t len_hash (char* str)
    {   
        assert (str);
        return strlen (str);
    }
#+END_SRC

4. =sum_of_letter_codes_hash=:

#+BEGIN_SRC C++
    uint64_t sum_of_letter_codes_hash (char* str)
    {
        assert (str);

        uint64_t hash = 0;

        while (*str++ != 0)
        {
            hash += (uint64_t) (*str);
        }

        return hash;
    }
#+END_SRC

5. =rol_hash=:

#+BEGIN_SRC C++
    uint64_t rol_hash (char* str)
    {   
        assert (str);

        const int shift_size_bits = CHAR_BIT * sizeof (uint64_t) - 1;
        const uint64_t highest_bit_mask = (uint64_t)1 << shift_size_bits;

        uint64_t hash = (uint64_t)str[0];
        
        while (*(str++) != 0)
        {
            hash = ((hash << 1) + ((hash & highest_bit_mask) >> shift_size_bits)) ^ (uint64_t)(*str);
        }

        return hash;
    }
#+END_SRC

6. =ror_hash=:

#+BEGIN_SRC C++
    uint64_t ror_hash (char* str)
    {
        assert (str);

        const int shift_size_bits = CHAR_BIT * sizeof (uint64_t) - 1;
        const int lowest_bit_mask = 1;

        uint64_t hash = (uint64_t)str[0];

        while (*(str++) != 0)
        {
            hash = ((hash >> 1) + ((hash & lowest_bit_mask) << shift_size_bits)) ^ (uint64_t)(*str);
        }

        return hash;
    }
#+END_SRC

7. =polynimial_rolling_hash=:

#+BEGIN_SRC C++
    uint64_t polynimial_rolling_hash (char* str)
    {
        assert (str);
        const int m = 1e9 + 9;
        const int p = 53;

        uint64_t hash = 0;
        uint64_t power = 1;

        while (*(str++) != 0)
        {
            hash = (hash + (uint64_t)((*str) - 'a' + 1) * power) % m;
            power = (p * power) % m;
        }

        return hash;
    }
#+END_SRC

Тестирование произоводилось следующим образом: 1. Создавалось два
объекта хэш-таблицы, с начальным размером в 50000 элементов. Одна
хэштаблица могла расширяться, вторая -- нет. 2. В хэш-таблицу
вставлялись элементы из словаря по описанному выше принципу. 3.
Производился замер времени вставки, вычислялась дисперсия распределения
длин подсписков (напомню, что каждый эелмент хэш-таблицы предствляет из
себя подсписок, это необходимо для разрешения коллизий).

По результатам работы были составлены следующие таблицы:

Для хэш-таблицы постоянного размера: 
| *Имя хэш-функции*             | *Дисперсия*   | *Время, секунды*  | *Размер таблицы*      |
|-------------------------------|---------------|-------------------|-----------------------|
| *const_hash*                  | nan           | 19.28271          | 50000                 | 
| *first_letter_code_hash*      | 3384202.89    | 1.15411           | 50000                 |
| *len_hash*                    | 4418417.99    | 2.86783           | 50000                 | 
| *sum_of_letter_codes_hash*    | 1049.22       | 0.07684           | 50000                 | 
|*ror_hash*                     | 16.776        | 0.02411           | 50000                 | 
| *rol_hash*                    | 5.044         | 0.01937           | 50000                 | 
| *polynimial_rolling_hash*     | 1.136         | 0.02191           | 50000                 |

Для расширяющейся хэш-таблицы: 
| *Имя хэш-функции*     | *Дисперсия* | *Время, секунды* | *Начальный размер таблицы* | *Конечный размер таблицы* |
|----------------------------------|---------------|--------------------|------------------------------|-----------------------------|
| *const_hash*                  | nan           | 23.9094 | 50000 | 100000 |
| *first_letter_code_hash*      | 3384202.89    | 1.76362 | 50000 | 100000 | 
| *len_hash*                    | 4418417.99    | 2.92111 | 50000 | 100000 | 
| *sum_of_letter_codes_hash*    | 1049.22       | 0.08114 | 50000 | 100000 | 
| *ror_hash*                    | 16.77         | 0.03716 | 50000 | 100000 | 
| *rol_hash*                    | 3.54          | 0.03268 | 50000 | 100000 | 
| *polynimial_rolling_hash*     | 0.661         | 0.03734 | 50000 | 100000 |

Из таблиц можно сделать следующие выводы: 1. Никогда не используйте
=cons_hash=, это бессмысленно.

2. Наилучшими оказались =rol_hash=, =ror_hash= и
   =polynimial_rolling_hash=.

3. По верхним строчкам таблицы может показаться, что добавление функции
   расширения, не дает ничего, кроме увелечения времени работы (при
   расширении нужно пересчитать хэш всех элементов), тем не менее, по
   нижним строчкам видно, что засчет расширения таблицы время вставки
   уменьшилось настолько сильно, что общее время работы либо
   уменьшилось, либо почти не изменилось. Это говорит о том, что функция
   расширения таблицы, в совокупности с хорошей хэш-функцией уменьшает
   время вставки.

4. Как и со временем работы, если посмотреть на верхние строчки таблицы,
   можно подумать, что увеличение размера таблицы никак не повлияло на
   дисперсию размеров бакетов, но вызвано это было плохой хэш-функцией.
   Если же посмотреть на нижние строчки таблицы, в которых предствлены
   относительно хорошие хэш-функции, можно понять, что увеличение
   размера таблицы на порядок уменьшило дисперсию.

Таким образом, были приняты следующие решения: 1. Использовать
=polynimial_rolling_hash= в качестве хэш-функции. 2. Оставить
хэш-таблицу расширяемой.

* Оптимизация
  :PROPERTIES:
  :CUSTOM_ID: оптимизация
  :END:

Теперь, когда мы выяснили, какие параметры таблицы использовать лучше
всего, перейдем к оптимизации.

Первым делом отметим каким образом мы тестировали хэш-таблицу на
производительность. Для этого приведем код функции =main= исполняемой
программы.

#+BEGIN_SRC C++
    int main()
    {
        Text csv_data = {};
        TextCtor (&csv_data, "../data/en-ru.csv");
        const size_t idx_arr_size = 256;
        int* idx_for_search_array = (int*) calloc (idx_arr_size, sizeof(*idx_for_search_array));

        HashTable<char*, char*> ht = {};
        HashTableCtor<char*, char*> (&ht, 50000, polynimial_rolling_hash, key_equality);

        FillIndexesArrayWithRandomValues (idx_for_search_array, idx_arr_size, csv_data.non_empty_lines);

        FillHashTableFromStrCSV (&csv_data, &ht);

        SearchSpeedTest (idx_for_search_array, idx_arr_size, &ht, &csv_data);

    }
#+END_SRC

Как видно из приведенного выше кода, если не вдаваться в детали
реализации, мы создавали массив из 256 ключей, который заполняли
случайными ключами из словаря, после этого мы искали все 256 ключей в
хэш-таблице.

Профилирование производилось при помощи утилиты =perf=. Для сбора
статистики запускалась следующая команда.

=sudo perf record -e cpu-clock,cache-misses,branch-misses --freq=10000 ./main=

Первый тест, без оптимизаций (в дальнейшем мы будем сравнивать
результаты оптимизаций с ним) дал следующие показатели:

#+BEGIN_HTML
  <details>
#+END_HTML

Результат первого теста.

#+BEGIN_SRC
# To display the perf.data header info, please use --header/--header-only options.
#
# dso: main
#
# Total Lost Samples: 0
#
# Samples: 340  of event 'cpu-clock'
# Event count (approx.): 34000000
#
# Overhead  Command  Symbol                                    
# ........  .......  ..........................................
#
    16.18%  main     [.] polynimial_rolling_hash
    15.88%  main     [.] HashTableInsert<char*, char*>
     6.47%  main     [.] LLIncreaseSize<HT_Pair<char*, char*> >
     2.06%  main     [.] LLInsertAfter<HT_Pair<char*, char*> >
     1.18%  main     [.] FillLinesArray
     1.18%  main     [.] 0x0000000000001270
     0.59%  main     [.] FillHashTableFromStrCSV
     0.59%  main     [.] 0x00000000000011f0
     0.29%  main     [.] key_equality
     0.29%  main     [.] main


# Samples: 282  of event 'cache-misses'
# Event count (approx.): 790389
#
# Overhead  Command  Symbol                                    
# ........  .......  ..........................................
#
    13.07%  main     [.] polynimial_rolling_hash
    12.88%  main     [.] HashTableInsert<char*, char*>
     8.18%  main     [.] LLIncreaseSize<HT_Pair<char*, char*> >
     0.92%  main     [.] key_equality
     0.60%  main     [.] HashTableFind<char*, char*>
     0.35%  main     [.] LLInsertAfter<HT_Pair<char*, char*> >
     0.33%  main     [.] main
     0.28%  main     [.] FillLinesArray
     0.19%  main     [.] FillHashTableFromStrCSV


# Samples: 248  of event 'branch-misses'
# Event count (approx.): 312338
#
# Overhead  Command  Symbol                                    
# ........  .......  ..........................................
#
    27.37%  main     [.] HashTableInsert<char*, char*>
     4.60%  main     [.] polynimial_rolling_hash
     1.13%  main     [.] FillLinesArray
     0.84%  main     [.] LLInsertAfter<HT_Pair<char*, char*> >
     0.78%  main     [.] LLIncreaseSize<HT_Pair<char*, char*> >
     0.36%  main     [.] FillHashTableFromStrCSV
     0.27%  main     [.] HashTableFind<char*, char*>


#
# (Cannot load tips.txt file, please install perf!)
#

#+END_SRC


#+BEGIN_HTML
  </details>
#+END_HTML

Первый тест выявил две проблемы:
1. Функция хэширования работает достаточно медленно для функции, которая вызывается при любой попытке вставить элемент или найти элемент по ключу
2. Вставка в хэш-таблицу довольно медленная, поскольку содержит операцию взятия остатка по составному числу

После первого теста было решено провести две оптимизации:
1. Сделать размер хэш-таблицы степенью двойки, что позволит использовать опреатор =&= вместо оператора =%=
2. Оптимизировать функцию =polynimial_rolling_hash=, а именно:
    1. Протестировать, сильно ли ухудшится хэш, если убрать оператор =%=.
    2. Если оптимизация выше не поможет, переписать часть или всю функцию на ассемблере.
3. Проверка бранч-мисов в функции =HashTableInsert<char*, char*>= выявила, что больше всего мисов происходит в строчках:

#+BEGIN_SRC
    if (hash_table->buckets[position].status == BUCKET_EMPTY)
#+END_SRC

На них приходится почти 85+% всех мисов в функции. Пока неясно, как это чинить, так что оставим напоследок.

Для начала мы протестировали новую хэш-функцию (без операции взятия остатка от деления), дисперсия оказалась такой же с точностью до -6 порядка, поэтому было принято решение убрать операцию взятия остатка от деления из хэша.

После этого, в конструкторе хэш-таблицы были добавлены следующие строки:

#+BEGIN_SRC
    int table_int_log = (int) ceil (log2 (table_size));
    table_size = pow (2, table_int_log);
#+END_SRC

Благодаря им, мы можем быть уверены, что размер таблицы всегда будет степенью двойки. Кроме того, было проверено, что при расширении хэш-таблицы ее размер увеличивается в кратное 2 число раз. В функции поиска положения по ключу строка =key_hash % hash_table->size= заменилась на =key_hash & (hash_table->size - 1)=.

На всякий случай, мы измерили дисперсию хэш-функции в измененной хэш-таблице, и она уменьшилась на 83% (=D_old = 0.6681=, =D_new = 0.5533=)/

Все оптимизации были проделаны, можно запускать второй тест.

#+BEGIN_HTML
  <details>
#+END_HTML

Резульат второго теста.

#+BEGIN_SRC
# To display the perf.data header info, please use --header/--header-only options.
#
# dso: main
#
# Total Lost Samples: 0
#
# Samples: 245  of event 'cpu-clock'
# Event count (approx.): 24500000
#
# Overhead  Command  Symbol                                    
# ........  .......  ..........................................
#
    19.59%  main     [.] HashTableInsert<char*, char*>
     7.76%  main     [.] polynimial_rolling_hash
     4.90%  main     [.] LLIncreaseSize<HT_Pair<char*, char*> >
     2.86%  main     [.] HashTableCtor<char*, char*>
     2.45%  main     [.] FillLinesArray
     2.04%  main     [.] LLInsertAfter<HT_Pair<char*, char*> >
     2.04%  main     [.] __HashTableGetPosition<char*, char*>
     0.82%  main     [.] FillHashTableFromStrCSV
     0.41%  main     [.] HashTableFind<char*, char*>
     0.41%  main     [.] 0x0000000000001230


# Samples: 213  of event 'cache-misses'
# Event count (approx.): 780701
#
# Overhead  Command  Symbol                                    
# ........  .......  ..........................................
#
    17.58%  main     [.] HashTableInsert<char*, char*>
     6.90%  main     [.] polynimial_rolling_hash
     3.62%  main     [.] LLIncreaseSize<HT_Pair<char*, char*> >
     2.20%  main     [.] LLInsertAfter<HT_Pair<char*, char*> >
     1.92%  main     [.] FillHashTableFromStrCSV
     1.11%  main     [.] __HashTableGetPosition<char*, char*>
     0.76%  main     [.] HashTableCtor<char*, char*>
     0.48%  main     [.] FillLinesArray
     0.46%  main     [.] HashTableFind<char*, char*>


# Samples: 182  of event 'branch-misses'
# Event count (approx.): 303806
#
# Overhead  Command  Symbol                                   
# ........  .......  .........................................
#
    31.23%  main     [.] HashTableInsert<char*, char*>
     3.68%  main     [.] LLInsertAfter<HT_Pair<char*, char*> >
     1.53%  main     [.] FillLinesArray
     1.17%  main     [.] __HashTableGetPosition<char*, char*>
     1.02%  main     [.] polynimial_rolling_hash
     0.42%  main     [.] FillHashTableFromStrCSV

#+END_SRC

#+BEGIN_HTML
  </details>
#+END_HTML
